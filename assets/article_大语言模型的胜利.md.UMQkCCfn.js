import{_ as t,c as a,ap as p,o as i}from"./chunks/framework.CCxIPCIe.js";const f=JSON.parse('{"title":"大语言模型的胜利","description":"","frontmatter":{"title":"大语言模型的胜利","date":"2024-08-29T12:10:35.332Z","length":"1883字","time":"7分钟","aside":false,"hash":282728175},"headers":[],"relativePath":"article/大语言模型的胜利.md","filePath":"article/大语言模型的胜利.md"}'),o={name:"article/大语言模型的胜利.md"};function _(r,e,n,l,s,c){return i(),a("div",null,e[0]||(e[0]=[p("<p>在我看来，大模型证明了两件事：</p><ol><li>语言能力不等于思维能力，从而人类智能不等于掌握语言的能力，或者说所谓的人工智能并非仅凭掌握人类语言的能力而诞生。</li><li>语言的无意识性</li></ol><p>莫拉维克悖论（Moravec&#39;s paradox）是由人工智能和机器人学者所发现的一个和常识相左的现象：和传统假设不同，人类所独有的高阶智慧能力只需要非常少的计算能力，例如推理，但是无意识的技能和直觉却需要极大的运算能力。这个理念是由汉斯·莫拉维克、罗德尼·布鲁克斯、马文·闵斯基等人于 1980 年代所阐释。如莫拉维克所写：“要让电脑如成人般地下棋是相对容易的，但是要让电脑有如一岁小孩般的感知和行动能力却是相当困难甚至是不可能的”。</p><p>这其实正印证了黑格尔的观点，即人类的最高能力是知性能力，而非理性能力。其中知性能力是将客观世界符号化的能力，而理性能力是知性的自反性，或者说是知性面对自己建构的符号学框架的反思性能力，也就包含着上文中人类的“高阶”智慧能力，比如符号系统的自组织和推演（形式逻辑）。我们知道，模拟以形式逻辑为代表的“高阶”智慧能力一度是人工智能的焦点（即符号主义时期），当时人们认为人类理性大部分在于这种形式逻辑能力，这方面的研究产生了大量的符号主义成果——如专家系统。然而人们发现符号主义无法攻克最基本的感知力——如模式识别（图像识别、语音识别等等），这种感知力恰恰就是知性，即如何从感性内容中提取出符号学模式；更无法攻克在当时看来人类智慧的至高结晶——语言。</p><p>而这种知性能力在联结主义时代，也即在神经网络技术加大数据支持下获得了相当长足的进步。同样的技术还被用于攻克语言，诞生出了有史以来被认为最强大的人工智能模型——大语言模型。符号主义无法解决的事情被联结主义解决了。</p><p>掌握“基本”感知力的模型能同样掌握“更为高等”的语言能力，这启发我们，语言能力也不过是一种“基本”感知力、一种知性能力——只不过这种知性能力的对象是已经知性化的符号（能指），带给我们一种更为高阶的错觉——正如大部分人认为的那样：“理性（知性的自反性）高于知性”。这也就是说，所谓的语言能力其实绝大部分雷同于“无意识的直觉”的基本感知力，也就是说语言活动是无意识的。</p><p>这个结论，恰恰又与拉康的语言学观点、无意识观点相符。无论我们将其表述为“语言是无意识的结构”还是“无意识像语言一样被结构”，都说明了一点，即与其说主体（人工智能试图模拟的对象）具有某种语言能力（或者说主体在言说），不如说是语言在使主体言说、符号系统不仅是先于主体、外在于主体的存在，结构出主体（能指主体、无意识主体），同样符号系统还在使主体言说，并使主体从言说中指认出我（所指主体）。</p><p>既然语言本身是无意识的、是他者的，那么它就不是主体所拥有的一件神秘物。当语言能力被大语言模型捕获，也就无所谓萌生出某种令人崇拜的神秘性。它无非是符号系统借助机器——有史以来第一次除人类以外的代理者（agent）加载、铺展自身引起的错觉——不它不是错觉，恰恰它颠覆了我们过去一直认定的关于语言能力的错觉。于是我们得知，主体不过是一具承载符号系统运转的符号学机器，在无意识的运作中指认出自我意识。过去拉康的晦涩观点，如今通过现代科技的进展再次面对世人宣讲。</p><p>当我们深入大语言模型的机理，我们又看见拉康对能指运作的深刻洞见。拉康倒置了索绪尔理论中能指-所指的关系，将能指放置在第一位，而所指不过是能指链滑行的意指效果，所谓的意义只能经过主体才能呈现。我们知道大语言模型所操作的基本单元，根本无所谓所指这些柏拉图意义上的漂浮在先验世界中的理念，而只是纯粹的符号，即 token（词元）。有的人也许要反驳，所谓的 token 本身是有意义的，它们或许是词根（lemma）或许是词缀（prefix，suffix，infix…），然而只需看看分词器（tokenizer）的工作原理（最经典的 BPE 算法）就可知道，它们纯粹是在序列长度和词表大小之间的算法权衡，抑或看看更激进的字节编码（Byte-level BPE），则从形式上根本放弃了人类可阅读性，而这些都正反映着索绪尔指出的任意性原则，只不过拉康将这一原则推向极致：在索绪尔那里，所指和能指的对应关系是任意的，但一旦固定下来便不再变化，而在拉康那里，这种固定的对应关系也根本不存在，对应也是任意的，甚至都不存在那个被对应的对象（所指），能指与所指是完全分隔的，我们只能操纵能指，而所指只是能指运作的效果，是一种运动。</p><p>回到大语言模型的例子，在最常见的 GPT 架构中，模型生成文本所做的事情就是 next token prediction（下一词元预测），这不正是能指链的滑移过程吗？这种滑移的动力，即符号系统的无意识自组织，被自回归概率模型模拟——自回归形式的条件概率模型捕捉了能指网络的拓扑学结构。当然，这种建模是片面的，即便我们假定能指网络是一个贝叶斯网络，它也需要苛刻的条件才能按此种方式分解（factorization）。我们大可不必较真统计方法近似再近似的不求甚解的“实用主义倾向”，毕竟 GPT 和能指网络之间的关系，不也正如能指与所指之间的关系一般，总有无可弥合的最小差异吗？我们的确看到的是，大语言模型对人类语言的模仿能力印证着符号系统自组织的结论，甚至那种一本正经的胡说八道的能力也是符号学空转的最佳案例。</p><p>因而可以说大模型的胜利是黑格尔的胜利、拉康的胜利。</p>",11)]))}const m=t(o,[["render",_]]);export{f as __pageData,m as default};
