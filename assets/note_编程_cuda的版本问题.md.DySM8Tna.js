import{_ as s,c as n,ao as e,o as p}from"./chunks/framework.n-91xA-b.js";const u=JSON.parse('{"title":"cuda 的版本问题","description":"","frontmatter":{"title":"cuda 的版本问题","date":"2025-07-11T07:22:17.641Z","length":"612字","time":"3分钟","aside":true,"hash":-1449406816},"headers":[],"relativePath":"note/编程/cuda的版本问题.md","filePath":"note/编程/cuda的版本问题.md"}'),o={name:"note/编程/cuda的版本问题.md"};function t(l,a,c,r,d,i){return p(),n("div",null,a[0]||(a[0]=[e(`<p>最近遇到一些 cuda 的版本问题，特来记录一下。</p><h2 id="分清几个概念" tabindex="-1">分清几个概念 <a class="header-anchor" href="#分清几个概念" aria-label="Permalink to &quot;分清几个概念&quot;">​</a></h2><table tabindex="0"><thead><tr><th>名称</th><th>版本号举例</th><th>查看版本方式</th><th>作用</th></tr></thead><tbody><tr><td>NVIDIA 驱动</td><td><code>535.104.05</code></td><td><code>modinfo nvidia | grep version</code></td><td>用于控制 GPU 硬件、提供 CUDA 支持</td></tr><tr><td>CUDA 运行时（runtime）</td><td><code>12.2</code> <code>11.8</code></td><td><code>torch.version.cuda</code></td><td>指程序运行所依赖的 <code>.so</code> 库，用于运行 PyTorch/CuPy</td></tr><tr><td>CUDA 工具箱（Toolkit）</td><td><code>12.2</code> <code>11.8</code></td><td><code>nvcc --version</code></td><td>包括 nvcc 编译器、头文件、运行时、开发工具等，用于编译</td></tr></tbody></table><p>而一般单说 CUDA 版本时，指的是 Toolkit 的版本。</p><h2 id="驱动与向后兼容" tabindex="-1">驱动与向后兼容 <a class="header-anchor" href="#驱动与向后兼容" aria-label="Permalink to &quot;驱动与向后兼容&quot;">​</a></h2><p>另外，输入命令 <code>nvidia-smi</code> 得到 CUDA version 实际上对应的是当前驱动所支持的最高 CUDA 版本，例如</p><div class="language-"><button title="Copy Code" class="copy"></button><span class="lang"></span><pre class="shiki solarized-dark vp-code" tabindex="0"><code><span class="line"><span>Fri Jul 11 11:07:18 2025       </span></span>
<span class="line"><span>+---------------------------------------------------------------------------------------+</span></span>
<span class="line"><span>| NVIDIA-SMI 535.216.01             Driver Version: 535.216.01   CUDA Version: 12.2     |</span></span>
<span class="line"><span>|-----------------------------------------+----------------------+----------------------+</span></span>
<span class="line"><span>| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |</span></span>
<span class="line"><span>| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |</span></span>
<span class="line"><span>|                                         |                      |               MIG M. |</span></span>
<span class="line"><span>|=========================================+======================+======================|</span></span>
<span class="line"><span>|   0  NVIDIA A40                     On  | 00000000:D8:00.0 Off |                    0 |</span></span>
<span class="line"><span>|  0%   23C    P8              28W / 300W |      0MiB / 46068MiB |      0%      Default |</span></span>
<span class="line"><span>|                                         |                      |                  N/A |</span></span>
<span class="line"><span>+-----------------------------------------+----------------------+----------------------+</span></span>
<span class="line"><span>                                                                                         </span></span>
<span class="line"><span>+---------------------------------------------------------------------------------------+</span></span>
<span class="line"><span>| Processes:                                                                            |</span></span>
<span class="line"><span>|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |</span></span>
<span class="line"><span>|        ID   ID                                                             Usage      |</span></span>
<span class="line"><span>|=======================================================================================|</span></span>
<span class="line"><span>|  No running processes found                                                           |</span></span>
<span class="line"><span>+---------------------------------------------------------------------------------------+</span></span></code></pre></div><p>说明该驱动最高支持 12.2 版本的 CUDA，由于驱动是向后兼容的，因此只要驱动足够新就可以兼容旧版本的 CUDA。例如上述驱动可以兼容基于 CUDA 11.8 的 PyTorch。</p><h2 id="不同版本" tabindex="-1">不同版本 <a class="header-anchor" href="#不同版本" aria-label="Permalink to &quot;不同版本&quot;">​</a></h2><p>如果系统中有不同版本的 CUDA Toolkit，则可以用命令 <code>ls -ld /usr/local/cuda*</code> 列出所有可用版本。通过</p><div class="language-bash"><button title="Copy Code" class="copy"></button><span class="lang">bash</span><pre class="shiki solarized-dark vp-code" tabindex="0"><code><span class="line"><span style="color:#93A1A1;font-weight:bold;">export</span><span style="color:#268BD2;"> PATH</span><span style="color:#859900;">=</span><span style="color:#268BD2;">$PATH</span><span style="color:#839496;">:/</span><span style="color:#268BD2;">usr</span><span style="color:#839496;">/</span><span style="color:#268BD2;">local</span><span style="color:#839496;">/</span><span style="color:#268BD2;">cuda-11</span><span style="color:#839496;">.</span><span style="color:#268BD2;">8</span><span style="color:#839496;">/</span><span style="color:#268BD2;">bin</span></span>
<span class="line"><span style="color:#93A1A1;font-weight:bold;">export</span><span style="color:#268BD2;"> LD_LIBRARY_PATH</span><span style="color:#859900;">=</span><span style="color:#268BD2;">$LD_LIBRARY_PATH</span><span style="color:#839496;">:/</span><span style="color:#268BD2;">usr</span><span style="color:#839496;">/</span><span style="color:#268BD2;">local</span><span style="color:#839496;">/</span><span style="color:#268BD2;">cuda-11</span><span style="color:#839496;">.</span><span style="color:#268BD2;">8</span><span style="color:#839496;">/</span><span style="color:#268BD2;">lib64</span></span></code></pre></div><p>来设置相应的版本（如上为 11.8）。</p><h2 id="pytorch-和-cuda" tabindex="-1">PyTorch 和 CUDA <a class="header-anchor" href="#pytorch-和-cuda" aria-label="Permalink to &quot;PyTorch 和 CUDA&quot;">​</a></h2><p><code>pip install torch</code> 的命令总是下载最新构建的 wheel，而这有时并不符合我们的需要。所以有时需要下载特定版本的 PyTorch，例如 <a href="https://download.pytorch.org/whl/cu118/torch-2.6.0+cu118-cp310-cp310-linux_x86_64.whl" target="_blank" rel="noreferrer">https://download.pytorch.org/whl/cu118/torch-2.6.0+cu118-cp310-cp310-linux_x86_64.whl</a> 这个路径下的 wheel，根据 Python Packaging User Guide 上的 <a href="https://packaging.python.org/en/latest/specifications/binary-distribution-format/#binary-distribution-format" target="_blank" rel="noreferrer">二进制发行版</a> 命名格式 <code>{distribution}-{version}(-{build tag})?-{python tag}-{abi tag}-{platform tag}.whl</code> 可知，它是基于 CUDA 11.8（cu118）和 CPython 3.10（cp310）构建的，因此其需要 CUDA 运行时版本为 11.8。</p><p>而通过 pip 下载的 wheel 也自带了相应版本的 CUDA 运行时，但有时 python 包路径下的 CUDA 运行时和系统路径下的 CUDA Toolkit 所包含的运行时版本可能冲突，因此最好用前面的方法指定对应版本的环境变量。</p>`,15)]))}const y=s(o,[["render",t]]);export{u as __pageData,y as default};
